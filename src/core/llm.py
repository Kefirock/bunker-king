import os
import json
import logging
import asyncio
import random
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from groq import AsyncGroq

try:
    from cerebras.cloud.sdk import Cerebras
except ImportError:
    Cerebras = None

from src.core.config import core_cfg

load_dotenv(os.path.join("Configs", ".env"))


class LLMService:
    def __init__(self):
        self.groq_key = os.getenv("GROQ_API_KEY")
        self.cerebras_key = os.getenv("CEREBRAS_API_KEY")

        self.groq_client = AsyncGroq(api_key=self.groq_key) if self.groq_key else None
        self.cerebras_client = Cerebras(api_key=self.cerebras_key) if (self.cerebras_key and Cerebras) else None

    async def generate(self,
                       model_config: Dict,
                       messages: List[Dict],
                       temperature: float = 0.7,
                       json_mode: bool = False,
                       logger=None) -> str:
        """
        Ð£Ð¼Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ Fallback. Ð•ÑÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð´Ñ€ÑƒÐ³Ð¸Ðµ.
        """
        # 1. ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ (ÐºÐ¾Ð¿Ð¸Ñ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¸ÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ‚ÑŒ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð» Ð¿Ñ€Ð¸ Ñ€ÐµÑ‚Ñ€Ð°ÑÑ…)
        current_messages = [m.copy() for m in messages]

        if json_mode:
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸ÑŽ JSON, ÐµÑÐ»Ð¸ ÐµÑ‘ Ð½ÐµÑ‚
            if not any("json" in (m.get("content") or "").lower() for m in current_messages):
                sys_msg = {"role": "system", "content": "ÐžÐ¢Ð’Ð•Ð¢Ð¬ Ð¡Ð¢Ð ÐžÐ“Ðž Ð’ JSON."}
                if current_messages and current_messages[0].get("role") == "system":
                    current_messages[0]["content"] += " ÐžÐ¢Ð’Ð•Ð¢Ð¬ Ð¡Ð¢Ð ÐžÐ“Ðž Ð’ JSON."
                else:
                    current_messages.insert(0, sys_msg)

        # 2. Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº
        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ, Ð¿Ð¾Ñ‚Ð¾Ð¼ 2 ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ð°ÑÐ½Ñ‹Ðµ
        candidates = [model_config]
        all_models = core_cfg.models.get("player_models", [])

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð¿Ð°ÑÐ½Ñ‹Ðµ (Ð¸ÑÐºÐ»ÑŽÑ‡Ð°Ñ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ)
        backups = [m for m in all_models if m != model_config]
        random.shuffle(backups)
        candidates.extend(backups[:2])

        # 3. Ð¦Ð¸ÐºÐ» Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº
        for i, config in enumerate(candidates):
            provider = config.get("provider")
            model_id = config.get("model_id")

            try:
                # Ð–ÐµÑÑ‚ÐºÐ¸Ð¹ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ 15 ÑÐµÐºÑƒÐ½Ð´ Ð½Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ
                response = await asyncio.wait_for(
                    self._call_provider(provider, model_id, current_messages, temperature, json_mode),
                    timeout=15.0
                )

                if response:
                    if logger:
                        logger.log_llm(model_id, current_messages, response)
                    return response

            except (asyncio.TimeoutError, Exception) as e:
                err_msg = f"LLM Error ({provider}/{model_id}): {e}"
                if logger: logger.log_event("ERROR", err_msg)
                print(f"âš ï¸ {err_msg} -> Switching to backup...")
                # Ð˜Ð´ÐµÐ¼ Ðº ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¼Ñƒ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ñƒ Ð² Ñ†Ð¸ÐºÐ»Ðµ

        # Ð•ÑÐ»Ð¸ Ð²ÑÐµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð¿Ñ€Ð¾Ð²Ð°Ð»Ð¸Ð»Ð¸ÑÑŒ
        print("ðŸ”¥ ALL LLM ATTEMPTS FAILED.")
        return "{}" if json_mode else "..."

    async def _call_provider(self, provider: str, model_id: str, messages: List[Dict], temp: float,
                             json_mode: bool) -> str:
        """ÐÐ¸Ð·ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð² API"""
        kwargs = {
            "model": model_id,
            "messages": messages,
            "temperature": temp,
            "max_tokens": 1024
        }

        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        if provider == "groq":
            if not self.groq_client: raise ValueError("Groq Client missing")
            completion = await self.groq_client.chat.completions.create(**kwargs)
            return completion.choices[0].message.content

        elif provider == "cerebras":
            if not self.cerebras_client: raise ValueError("Cerebras Client missing")
            completion = self.cerebras_client.chat.completions.create(**kwargs)
            return completion.choices[0].message.content

        else:
            raise ValueError(f"Unknown provider: {provider}")

    @staticmethod
    def parse_json(text: Optional[str]) -> Dict[str, Any]:
        if not text: return {}
        clean_text = text.replace("```json", "").replace("```", "").strip()
        try:
            return json.loads(clean_text)
        except:
            return {}


llm_client = LLMService()