import uuid
import random
from typing import List, Tuple, Dict
from src.core.llm import llm_client
from src.core.config import core_cfg
from src.games.detective.config import detective_cfg
from src.games.detective.schemas import DetectiveScenario, Fact, FactType, RoleType, DetectivePlayerProfile


class ScenarioGenerationError(Exception):
    pass


class ScenarioGenerator:
    async def generate(self, player_names: List[str], logger=None) -> Tuple[
        DetectiveScenario, Dict[str, DetectivePlayerProfile]]:
        count = len(player_names)
        model = core_cfg.models["player_models"][0]
        max_attempts = 3

        # --- –®–ê–ì 1: –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–Æ–ñ–ï–¢–ê –ò –†–û–õ–ï–ô ---

        master_prompt = detective_cfg.prompts["scenario_master"]["system"].format(
            player_count=count
        )

        scenario_data = None

        if logger: logger.log_event("GEN_STEP_1", "Generating Master Scenario")

        for attempt in range(1, max_attempts + 1):
            try:
                print(f"üß† –®–∞–≥ 1: –°—é–∂–µ—Ç ({attempt}/{max_attempts})...")
                response = await llm_client.generate(
                    model_config=model,
                    messages=[{"role": "system", "content": master_prompt}],
                    temperature=0.8,
                    json_mode=True
                )
                data = llm_client.parse_json(response)

                # –í–∞–ª–∏–¥–∞—Ü–∏—è
                required_fields = ["roles", "victim", "solution"]
                if not data or any(f not in data for f in required_fields) or len(data["roles"]) < count:
                    print("‚ö†Ô∏è –®–∞–≥ 1: –û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.")
                    continue

                scenario_data = data
                break
            except Exception as e:
                print(f"‚ö†Ô∏è –®–∞–≥ 1 –û—à–∏–±–∫–∞: {e}")
                continue

        if not scenario_data:
            raise ScenarioGenerationError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—é–∂–µ—Ç.")

        # --- –®–ê–ì 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –£–õ–ò–ö (–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø) ---

        # –ü–µ—Ä–µ–¥–∞–µ–º –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Ñ–∞–∫—Ç–æ–≤
        roles_desc = []
        for r in scenario_data["roles"]:
            roles_desc.append(
                f"- –ò–º—è: {r.get('character_name')} ({r.get('tag')})\n"
                f"  –†–æ–ª—å: {r.get('role')}\n"
                f"  –õ–µ–≥–µ–Ω–¥–∞: {r.get('legend')}\n"
                f"  –°–µ–∫—Ä–µ—Ç: {r.get('secret')}"
            )

        facts_prompt = detective_cfg.prompts["fact_generator"]["system"].format(
            victim=scenario_data.get("victim"),
            cause=scenario_data.get("cause_of_death"),
            location=scenario_data.get("location_of_body"),
            solution=scenario_data.get("solution"),
            characters_list="\n".join(roles_desc)
        )

        facts_data_map = {}

        if logger: logger.log_event("GEN_STEP_2", "Generating Facts")

        try:
            print(f"üß† –®–∞–≥ 2: –£–ª–∏–∫–∏ (–§–∞–∫—Ç—É—Ä–∞)...")
            response_facts = await llm_client.generate(
                model_config=model,
                messages=[{"role": "system", "content": facts_prompt}],
                temperature=0.85,  # –í—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–∞ –≤ –¥–µ—Ç–∞–ª—è—Ö
                json_mode=True
            )
            parsed_facts = llm_client.parse_json(response_facts)

            for item in parsed_facts.get("facts_by_character", []):
                facts_data_map[item.get("character_name")] = item.get("facts", [])

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∞–∫—Ç–æ–≤: {e}")
            if logger: logger.log_event("GEN_FACTS_ERROR", str(e))

        # --- –°–ë–û–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê ---
        return self._assemble_game_objects(scenario_data, facts_data_map, player_names)

    def _assemble_game_objects(self,
                               scen_data: Dict,
                               facts_map: Dict,
                               player_names: List[str]) -> Tuple[DetectiveScenario, Dict[str, DetectivePlayerProfile]]:

        scenario = DetectiveScenario(
            title=scen_data.get("title", "–î–µ–ª–æ –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
            description=scen_data.get("description", "..."),
            victim_name=scen_data.get("victim", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"),
            time_of_death=scen_data.get("time_of_death", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
            cause_of_death=scen_data.get("cause_of_death", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
            location_of_body=scen_data.get("location_of_body", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
            murder_method=scen_data.get("method", "Unknown"),
            true_solution=scen_data.get("solution", "Unknown")
        )

        player_profiles: Dict[str, DetectivePlayerProfile] = {}
        roles_data = scen_data.get("roles", [])

        random.shuffle(roles_data)

        for i, real_name in enumerate(player_names):
            role_json = roles_data[i] if i < len(roles_data) else roles_data[0]

            char_name = role_json.get("character_name", f"–ü–µ—Ä—Å–æ–Ω–∞–∂ {i + 1}")
            r_str = str(role_json.get("role", "INNOCENT")).upper()
            role_enum = RoleType.KILLER if "KILLER" in r_str else RoleType.INNOCENT

            profile = DetectivePlayerProfile(
                character_name=char_name,
                tag=role_json.get("tag", "–ì–æ—Å—Ç—å"),
                legend=role_json.get("legend", ""),
                role=role_enum,
                secret_objective=role_json.get("secret", "")
            )

            # –î–æ—Å—Ç–∞–µ–º —Ñ–∞–∫—Ç—ã –ø–æ –∏–º–µ–Ω–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            # (–ò–Ω–æ–≥–¥–∞ LLM —á—É—Ç—å –º–µ–Ω—è–µ—Ç –∏–º—è, –ø–æ—ç—Ç–æ–º—É –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å fuzzy match, –Ω–æ –ø–æ–∫–∞ —Å—Ç—Ä–æ–≥–æ)
            raw_facts = facts_map.get(char_name, [])

            # Fallback
            while len(raw_facts) < 5:
                raw_facts.append({
                    "text": f"–Ø –∑–∞–º–µ—Ç–∏–ª —á—Ç–æ-—Ç–æ —Å—Ç—Ä–∞–Ω–Ω–æ–µ –≤–æ–∑–ª–µ {scenario.location_of_body}, –Ω–æ –Ω–µ –ø—Ä–∏–¥–∞–ª –∑–Ω–∞—á–µ–Ω–∏—è.",
                    "keyword": "–°—Ç—Ä–∞–Ω–Ω–æ—Å—Ç—å",
                    "type": "TESTIMONY"
                })

            for f_data in raw_facts[:5]:
                fid = str(uuid.uuid4())[:8]

                ftype_str = str(f_data.get("type", "TESTIMONY")).upper()
                if "PHYSICAL" in ftype_str:
                    ftype = FactType.PHYSICAL
                elif "MOTIVE" in ftype_str:
                    ftype = FactType.MOTIVE
                elif "ALIBI" in ftype_str:
                    ftype = FactType.ALIBI
                else:
                    ftype = FactType.TESTIMONY

                keyword = f_data.get("keyword", "–£–ª–∏–∫–∞")
                if len(keyword) > 20: keyword = keyword[:20] + "."

                fact = Fact(
                    id=fid,
                    text=f_data.get("text", "???"),
                    keyword=keyword,
                    type=ftype,
                    is_public=False
                )

                scenario.all_facts[fid] = fact
                profile.inventory.append(fid)

            player_profiles[real_name] = profile

        return scenario, player_profiles